{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff7fe18-4d14-4384-8fdc-9dc535cd8a6a",
   "metadata": {},
   "source": [
    " \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a8aa71-cb0b-4a13-8792-00a2fa4de64d",
   "metadata": {},
   "source": [
    "**Q. How to create Schema in PySpark**\n",
    "****\n",
    "**A.** There is three way to create\n",
    "- String\n",
    "  - `schema = \"id int, name string, salary float, date_of_joining date\"`\n",
    "- structType([structField(col(\"id\"), integerType(), null=True)])\n",
    "  - `structType([`                  \n",
    "  - `    structField(col(\"id\"), integerType(), null=True)`\n",
    "  - `    structField(col(\"name\"), stringType(), null= True)`\n",
    "  - `    structField(col(\"salary\"), floatType(), null= True)`\n",
    "  - `    structField(col(\"id\"), stringType(), null= True)`\n",
    "  - `    structField(col(\"date_of_joining\"), dateType(), null= True)])`\n",
    "- structType().add()\n",
    "  - `structType().add(\"name\", StringType(), nullable = True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c89643-05cc-4a14-ab3a-d3e721f425dc",
   "metadata": {},
   "source": [
    "**Q. What is the structType and structField in schema**\r\n",
    "****\r\n",
    "**A.**`structType()`: Define structure of Dataframe          \n",
    "`fieldType()`: Define metadata of the Dataframe columns\n",
    " \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3718f074-dfcb-4a5c-a949-c170b091fce1",
   "metadata": {},
   "source": [
    "**Q. What if I have a header in my DataFrame**\n",
    "****\n",
    "**A.** Use `option(\"header\", True)` or skip this header `option(\"skipRows\", 4)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bff556-c65e-4ee0-884a-ec6bd2f1ee59",
   "metadata": {},
   "source": [
    "**Q. How to create schema for struct and array**\n",
    "***\n",
    "**A.**\n",
    "\n",
    "\n",
    "`schema_with_struct = StructType([`                   \n",
    "`    StructField(\"id\", StringType(), True),`             \n",
    "`    StructField(\"details\", StructType([`                     \n",
    "`        StructField(\"name\", StringType(), True),`                \n",
    "`        StructField(\"age\", StringType(), True)`                   \n",
    "`    ]), True),`                                         \n",
    "`    StructField(\"score\", StringType(), True)`                             \n",
    "`])`                                          \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "`schema_with_array = StructType([`                 \n",
    "`    StructField(\"id\", StringType(), True),`                 \n",
    "`    StructField(\"names\", ArrayType(StringType()), True),`                        \n",
    "`    StructField(\"score\", StringType(), True)`                     \n",
    "`])`                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbcc4da-924b-45cd-a57f-a38b1b3f74f1",
   "metadata": {},
   "source": [
    "**Q. Have you worked with corrupted records**\n",
    "****\n",
    "**A.** Yes! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f9591-131c-4e2a-bd22-81aead636dce",
   "metadata": {},
   "source": [
    "**Q. When do you say that records are corrupted**\r\n",
    "****\r\n",
    "**A*.* \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ca889-b0f2-4392-9d32-fd2604384ad2",
   "metadata": {},
   "source": [
    "**Q. What happens when we encounter corrupted records in different read modes**\r\n",
    "****\r\n",
    "**A.**`option(\"mode\", \"PERMISSIVE\")`: Set null value to all corrupted fields              \n",
    "`option(\"mode\", \"DROPMALFORMED\")`: Drop the corrupted record/row              \n",
    "`option(\"mode\", \"FAILFAST\")`: Fail execution if malformed record in dataset              \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33707391-dbb5-4090-85e0-7b15115fdc88",
   "metadata": {},
   "source": [
    "**Q. How can we print bad records**\n",
    "****\n",
    "**A.** Create a dataframe schema ans this column `StructType([StructField(\"_corrupt_record\", StringType(), nullable = True)])`\r\n",
    " \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f0f04-c6a1-4f0e-aff5-88d0f3225fd6",
   "metadata": {},
   "source": [
    "**Q. List of Spark Data Types**\n",
    "***\n",
    "**A.**\n",
    "\n",
    "<table><tbody><tr><td>StringType</td><td>ShortType</td></tr><tr><td>ArrayType</td><td>IntegerType</td></tr><tr><td>MapType</td><td>LongType</td></tr><tr><td>StructType</td><td>FloatType</td></tr><tr><td>DateType</td><td>DoubleType</td></tr><tr><td>TimestampType</td><td>DecimalType</td></tr><tr><td>BooleanType</td><td>ByteType</td></tr><tr><td>CalendarIntervalType</td><td>HiveStringType</td></tr><tr><td>BinaryType</td><td>ObjectType</td></tr><tr><td>NumericType</td><td>NullType</td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a8ce47-c646-47fc-bb9a-6593ff2e393c",
   "metadata": {},
   "source": [
    "**Q. Where do you store corrupted records and how can we access them later**\n",
    "****\n",
    "**A.** Assign a path to store bad record `option(\"badRecordsPath\",\"/file/store/data/\")`\n",
    "\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f25bc-dfb3-497c-915d-013ace140711",
   "metadata": {},
   "source": [
    "**Q. What is JSON data and how to read it in Apache PySpark**\n",
    "****\n",
    "**A.** JSON standard for JavaScript Object Notation is a semi-structured data, store data in key:value pair, use ` format(\"json\") ` \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bfaf9f-32c0-4146-968c-bd793d1b88b4",
   "metadata": {},
   "source": [
    "**Q. What if I have 3 keys in all lines and 1 key in one line in the JSON file**\n",
    "****\n",
    "**A.** Create 4 columns in dataframe and assign 4<sup>th</sup> column null if value is not persent \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb39868d-85c8-4fbd-8ea4-90e2fda124e8",
   "metadata": {},
   "source": [
    "**Q. What is multi-line and line-delimited JSON**\n",
    "****\n",
    "**A.**                        \n",
    "**1. Multi-line** : Where JSON single record in more than one line                \n",
    "`          {`                     \n",
    "`            \"name\":\"Nazer\",`                  \n",
    "`            \"email\":\"naziri1920@gmail.com\"`              \n",
    "`            \"mobile\": 5847896542`                    \n",
    "`          }`                   \n",
    "\n",
    "**2. line-delimited**: Single line JSON                  \n",
    "`          {\"name\":\"Nazer\",\"email\":\"naziri1920@gmail.com\",\"mobile\":123456790}`\n",
    " \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7da15-88f2-433d-af82-4a6d08241dfb",
   "metadata": {},
   "source": [
    "**Q. Which one works faster: multi-Line or Line-delimited in JSON in file format**\n",
    "****\n",
    "**A.** line-delimited work fister bucause by derault spark consider JSON line-delimited\n",
    " \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb448d78-ef39-4580-bf9a-bea5e103c4ca",
   "metadata": {},
   "source": [
    "**Q. How to convert nested JSON into PySpark DataFrame**\n",
    "****\n",
    "**A.** Use ` option(\"multiline\", True) ` and ` format(\"json\") `\n",
    " \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be005bb-210b-499f-ad59-227e1192b799",
   "metadata": {},
   "source": [
    "**Q. What will happen if I have a corrupted JSON record and corrupted file**\n",
    "****\n",
    "**A.**  In case of corrupted record, this record is saved in _curropt_record column. In case of corrupted file return error. \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07602c-4669-4ee4-8f80-4a8ce4867d0f",
   "metadata": {},
   "source": [
    "**Q. What is Parquet as a file format**\n",
    "****\n",
    "**A.** Parquet is a default file format in Pyspark. There is not required any format \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d2e28-7696-4d7a-85a0-da7023cb038d",
   "metadata": {},
   "source": [
    "**Q. Why do we need Parquet**\n",
    "****\n",
    "**A.** Parquet is a columnar file format, and columnar file format is easy to read and process, low storage required, saved in hybrid form(data divided into column and rows), \n",
    " \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d86450-f073-4040-9471-c721a6e29626",
   "metadata": {},
   "source": [
    "**Q. How to read a Parquet file**\n",
    "****\n",
    "**A.** \n",
    "`spark.read.option(\"header\", True).load(\"file path\")` There is not necessary to provide format\n",
    " \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d1124-24df-4f9c-8d02-33845ad3a9ff",
   "metadata": {},
   "source": [
    "**Q. What makes Parquet the default choice**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea596f2-0849-4ece-92b9-472c784f2f46",
   "metadata": {},
   "source": [
    "**Q. What encoding is done on Parquet data**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8f6b2-5748-4205-9048-786407f59d1f",
   "metadata": {},
   "source": [
    "**Q. What comparison technique is used in the Parquet file format**\n",
    "****\n",
    "**A.** ` gzip ` comparison technique\n",
    " \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49316385-e9a0-4c28-b8d6-fbc4e57e0879",
   "metadata": {},
   "source": [
    "**Q. How to optimize the Parquet file**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea56e8-b83f-4af4-ad5c-ea5490c4f239",
   "metadata": {},
   "source": [
    "**Q. What are the modes available in DataFrame write**\n",
    "****\n",
    "**A.**                                                                    \n",
    "` mode(\"append\") `: Appends the data to the existing data if it exists.                          \n",
    "` mode(\"overwrite\") `: Overwrites the existing data if it exists.                                  \n",
    "` mode(\"ignore\") `: Ignores the operation if the data already exists.                                  \n",
    "` mode(\"error\") `: Raises an error if the data already exists.                                  \n",
    "` mode(\"errorifexist\") `: Raises an error if the data already exists.                                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5911be9a-5c75-41e7-9c0c-b9075b228baa",
   "metadata": {},
   "source": [
    "**Q. What is Partition By and Bucket**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae3fc73-62da-4133-84a0-664701aa7ff2",
   "metadata": {},
   "source": [
    "**Q. How to write data into multiple partitions**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f90ee-32bc-461e-985d-d9c45f15bde0",
   "metadata": {},
   "source": [
    "**Q. What is a partition in Apache Spark**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3397c7e7-602a-4641-afb7-efbbe5c1b38f",
   "metadata": {},
   "source": [
    "**Q. What is a bucket in Apache Spark**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c34847-a353-451c-a965-0c7a8adf4d24",
   "metadata": {},
   "source": [
    "**Q. Why do we need these two: partitioning and bucketing**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c851b0f-362a-4e74-a340-aef861e5b5c5",
   "metadata": {},
   "source": [
    "**Q. When to use partitioning**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19739fa0-c6d0-4dfa-87a8-373fe70e8843",
   "metadata": {},
   "source": [
    "**Q. When to use bucketing**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414baf6-82f8-461f-817d-a6a40a199495",
   "metadata": {},
   "source": [
    "\r\n",
    "**Q. What is schema**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07493e6e-b531-4a9f-b7df-0fcbee34d021",
   "metadata": {},
   "source": [
    "**Q. What is DataFrame**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004fab3f-b713-4a2d-bff5-08841dd1f270",
   "metadata": {},
   "source": [
    "**Q. How to select columns**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db199c3b-e888-4aa0-89bf-587ac331a49a",
   "metadata": {},
   "source": [
    "**Q. How many ways to select columns**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b76fdb-d73b-47bc-9f94-07be8b599b5c",
   "metadata": {},
   "source": [
    "**Q. What is the expression**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4261e64-f42b-4f33-a518-cd57a77d7893",
   "metadata": {},
   "source": [
    "**Q. What is aliasing**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc96df88-47c1-4925-9fa4-f0be0d349329",
   "metadata": {},
   "source": [
    "**Q. What is the difference between filter and where in Apache PySpark**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc62ff-73fc-46fc-9267-5ed948f05a67",
   "metadata": {},
   "source": [
    "**Q. What is the literal function**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f40c31-7f6a-4ce5-be0f-96f927779e79",
   "metadata": {},
   "source": [
    "**Q. How to add a new column in DataFrame**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff46d8a-74bf-40a5-a8b3-932c5d7793fd",
   "metadata": {},
   "source": [
    "**Q. How to rename a column in DataFrame**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ebb26-1178-4bb6-8b33-6d8b92731382",
   "metadata": {},
   "source": [
    "\r\n",
    "**Q. How to cast data types**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae165418-7ffa-4eca-8c93-c881090dcb3d",
   "metadata": {},
   "source": [
    "**Q. How to remove a column in DataFrame**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485606f-c5c7-46d2-a578-3bd25e4f7f13",
   "metadata": {},
   "source": [
    "\r\n",
    "**Q. What is the difference between Union and union all**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57583916-c562-4c27-81aa-cc627ce3493e",
   "metadata": {},
   "source": [
    "**Q. What will happen if I change the number of columns while Union in the data**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545699b6-324f-4742-b4c7-b7f6a2a24079",
   "metadata": {},
   "source": [
    "\r\n",
    "**Q. What if the column name is different**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31903030-7a4d-4f9c-9c9e-3b33c0e8fc20",
   "metadata": {},
   "source": [
    "\r\n",
    "**Q. What is UnionByName**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687bd109-0083-4428-9688-c2ae47b9c5e3",
   "metadata": {},
   "source": [
    "**Q. What is the case when in Spark SQL**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ae1e7-2c54-4dda-a903-7adef3d3b444",
   "metadata": {},
   "source": [
    "**Q. What is the when otherwise in Spark**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c875860-d189-46e2-b1fb-2f6dd55bf65f",
   "metadata": {},
   "source": [
    "**Q. How to deal with Null value in DataFrame**\r\n",
    "****\r\n",
    "**A.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d6381-85d3-4a29-927a-ca86964a43fc",
   "metadata": {},
   "source": [
    "**Q. How to use case when or when otherwise with multiple AND, OR conditions**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06bdb87-ee43-437b-96e3-5bd8dae7b321",
   "metadata": {},
   "source": [
    "**Q. How to find unique rows**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb7436-ad57-4239-a420-f800d5a4dfb7",
   "metadata": {},
   "source": [
    "**Q. How to drop duplicate rows**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd2eb84-ed97-4dc1-8197-a46b3615118d",
   "metadata": {},
   "source": [
    "**Q. How to sort the data in ascending and descending order**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba372d28-d606-4b7a-8dfd-a903c705dd8e",
   "metadata": {},
   "source": [
    "**Q. One sample question of PySpark**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae64b6d-44ad-4f94-9515-36fc3a0a82b6",
   "metadata": {},
   "source": [
    "**Q. How to use aggregation in PySpark**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b88a2-454d-4c51-bfd3-b6e32ad47e55",
   "metadata": {},
   "source": [
    "**Q. How groupBy works**\r\n",
    "****\r\n",
    "**A.** \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccc09b-03b7-4239-9a9d-7589b49130e8",
   "metadata": {},
   "source": [
    "**Q. How to implement groupBy in PySpark**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0038cc3e-d9fc-4c3b-8735-31e04d7f9003",
   "metadata": {},
   "source": [
    "**Q. How join works**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e60b9a3-bd7f-4f11-af11-4d5d83bac4b0",
   "metadata": {},
   "source": [
    "\r\n",
    "**Q. Why do we need join**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fbad46-47b8-4234-b8a0-77ff0a7d973a",
   "metadata": {},
   "source": [
    "\r\n",
    "**Q. What to do after joining two tables**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1672d74a-8f01-44d8-8e11-8d1a43c8533f",
   "metadata": {},
   "source": [
    "**Q. What if tables have the same column name**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542666a-6e13-4d6d-8049-71f33536e335",
   "metadata": {},
   "source": [
    "**Q. How to join on two more columns**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609621b-0f94-4c66-bef0-8776178fd3e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fffe340-d4b5-4cc8-aae5-7e88ba3d683d",
   "metadata": {},
   "source": [
    "**Q. How many types of join**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5aa581-456a-4ea4-8893-131240d54388",
   "metadata": {},
   "source": [
    "**Q. What is the window function**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aad615-772a-494c-81f5-baf4d761e25b",
   "metadata": {},
   "source": [
    "**Q. What is the row number rank dense rank in PySpark**\r\n",
    "****\r\n",
    "**A.** \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f91d1b-6b31-4b73-8072-0080f4a9ea65",
   "metadata": {},
   "source": [
    "**Q. How to calculate the top two salary holders from each department**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad52fb-c725-4203-86dd-7159968cfda6",
   "metadata": {},
   "source": [
    "\r\n",
    "**Q. What is LEAD and LAG in PySpark**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5c5d2-a5ff-455b-ab9b-228a567b9cd6",
   "metadata": {},
   "source": [
    "**Q. What is nested JSON in PySpark**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ccf57e-1a8d-4c37-88be-91dee433c565",
   "metadata": {},
   "source": [
    "**Q. What is SCD2**\r\n",
    "****\r\n",
    "**A.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16956d36-797b-4529-b43b-2f1f6a2edd68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7516f481-334f-48b6-a5b7-5de80a8592d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cec21dbb-694d-45b1-af81-6010cbd3cdf9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdd588b4-7eb7-4d82-b8de-f07d60a1fcf5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e353bfd-6b1c-4da4-aace-31096bff73cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63dacedb-d308-4616-b754-cd000d1f3798",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e020a95-5ee7-446e-bb4f-5f35e89f91c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d481b21-d548-4b31-a3eb-e2ca5ede1c04",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3536132-1a51-4e18-9ba0-7bf24effdb1d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60141464-a4a7-4d19-bec3-ea38112d8977",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52a76732-2819-46ed-b415-642af44ee084",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66820c9e-bcac-4535-b959-fa045c82ac03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bacc362-30c0-4fcf-bff7-64e4856bd976",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe317be4-1f27-44b7-865e-6db1fb438daf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f0f4e15-823b-46c3-b9f4-ea1a5e1d61cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac4c7e70-30b5-4390-ab97-ce597ddbdd90",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4adbc8d5-22fb-4d4a-8d13-7e499722f194",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "351667d6-cd69-4d62-8b3d-8741ec65949b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7d5f94-452a-42d1-bd8c-2f91e39a227f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a605fb-2385-4ecd-81f2-95393c445c1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9a8074-9255-4ff0-813d-accd9bf1f116",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c64b7a5-0429-4e7a-8f6d-60816d4f4615",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38013cd8-462e-42e8-8172-3d2705e2c5b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39d494ba-afe5-49c3-8070-290057c2f46f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e395e7-6e79-4a27-b2c6-1a6cf194b168",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "796cab99-b6c0-486e-9a6b-9465ee7ecbdf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae21ef33-96e8-4aef-864f-1dbf1e39c789",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd986f30-5111-4c3d-9ca0-b067299ab65e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b738144f-4426-4e84-a685-24ea6b69da66",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08e43e10-e998-41a4-9118-b081ef2ba2f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d315d17-81c7-4c05-a29e-455da3e8b0d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7906769c-a324-40fe-a92c-9efcffd045cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15e57272-00a4-48e4-9a13-159dd701381c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ca0c438-75c7-42c1-b7b2-29f3419688ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ddf9b8d-013e-4e64-b4ff-fca3dde0b165",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "615c989d-d2e1-4266-ac72-abc395679911",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdac8581-2002-477c-8acb-2f39022a9018",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a18ceab-e019-48b3-90a5-a60e0b8160b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50bf0f59-bca6-4167-85f4-f43d35c2d130",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9f0daf-f948-401a-a2be-5d3c64dcb38e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3493d48-0a40-4e52-8edb-7465a32d35e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc544aa6-0c04-4d92-a9cc-2121f89782c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "734312f8-573f-4aa3-8b1e-6873241ef7cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee5b6f5c-2809-4c3a-911d-8ad7e3b3a172",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78fbb1a2-c4ad-47ad-8e33-91ac9a7a2af3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a895713-adb9-4c59-a1d9-64af621f35d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89b21938-cdd3-492c-917d-7b50297d1128",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
